{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMuCnebwfUcI"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rEIfJ1pViUT",
        "outputId": "e504052e-ca64-408e-ffe5-232e8751ccc6"
      },
      "source": [
        "# Load Person Validation Set\n",
        "\n",
        "!wget https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/2.png -P PersonalValidationSet\n",
        "!wget https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/1.png -P PersonalValidationSet\n",
        "!wget https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/3.png -P PersonalValidationSet\n",
        "!wget https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/4.png -P PersonalValidationSet\n",
        "!wget https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/6.png -P PersonalValidationSet\n",
        "!wget https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/5.png -P PersonalValidationSet\n",
        "!wget https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/7.png -P PersonalValidationSet\n",
        "!wget https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/8.png -P PersonalValidationSet\n",
        "!wget https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/9.png -P PersonalValidationSet\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-08 00:35:42--  https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/2.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30673 (30K) [image/png]\n",
            "Saving to: ‘PersonalValidationSet/2.png.3’\n",
            "\n",
            "\r2.png.3               0%[                    ]       0  --.-KB/s               \r2.png.3             100%[===================>]  29.95K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-10-08 00:35:42 (8.90 MB/s) - ‘PersonalValidationSet/2.png.3’ saved [30673/30673]\n",
            "\n",
            "--2021-10-08 00:35:42--  https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/1.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26329 (26K) [image/png]\n",
            "Saving to: ‘PersonalValidationSet/1.png.2’\n",
            "\n",
            "1.png.2             100%[===================>]  25.71K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-10-08 00:35:42 (18.9 MB/s) - ‘PersonalValidationSet/1.png.2’ saved [26329/26329]\n",
            "\n",
            "--2021-10-08 00:35:42--  https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/3.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29653 (29K) [image/png]\n",
            "Saving to: ‘PersonalValidationSet/3.png.2’\n",
            "\n",
            "3.png.2             100%[===================>]  28.96K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-10-08 00:35:42 (8.72 MB/s) - ‘PersonalValidationSet/3.png.2’ saved [29653/29653]\n",
            "\n",
            "--2021-10-08 00:35:42--  https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/4.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32751 (32K) [image/png]\n",
            "Saving to: ‘PersonalValidationSet/4.png.2’\n",
            "\n",
            "4.png.2             100%[===================>]  31.98K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-10-08 00:35:42 (20.3 MB/s) - ‘PersonalValidationSet/4.png.2’ saved [32751/32751]\n",
            "\n",
            "--2021-10-08 00:35:42--  https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/6.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33067 (32K) [image/png]\n",
            "Saving to: ‘PersonalValidationSet/6.png.2’\n",
            "\n",
            "6.png.2             100%[===================>]  32.29K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-10-08 00:35:42 (10.7 MB/s) - ‘PersonalValidationSet/6.png.2’ saved [33067/33067]\n",
            "\n",
            "--2021-10-08 00:35:42--  https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/5.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33404 (33K) [image/png]\n",
            "Saving to: ‘PersonalValidationSet/5.png.2’\n",
            "\n",
            "5.png.2             100%[===================>]  32.62K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-10-08 00:35:42 (6.10 MB/s) - ‘PersonalValidationSet/5.png.2’ saved [33404/33404]\n",
            "\n",
            "--2021-10-08 00:35:42--  https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/7.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29100 (28K) [image/png]\n",
            "Saving to: ‘PersonalValidationSet/7.png.2’\n",
            "\n",
            "7.png.2             100%[===================>]  28.42K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-10-08 00:35:43 (19.6 MB/s) - ‘PersonalValidationSet/7.png.2’ saved [29100/29100]\n",
            "\n",
            "--2021-10-08 00:35:43--  https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/8.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38080 (37K) [image/png]\n",
            "Saving to: ‘PersonalValidationSet/8.png.2’\n",
            "\n",
            "8.png.2             100%[===================>]  37.19K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2021-10-08 00:35:43 (8.59 MB/s) - ‘PersonalValidationSet/8.png.2’ saved [38080/38080]\n",
            "\n",
            "--2021-10-08 00:35:43--  https://raw.githubusercontent.com/Mandaranian-Cactus/MNIST-CNN/main/Personal%20Validation%20Set/9.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36660 (36K) [image/png]\n",
            "Saving to: ‘PersonalValidationSet/9.png.2’\n",
            "\n",
            "9.png.2             100%[===================>]  35.80K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-10-08 00:35:43 (5.77 MB/s) - ‘PersonalValidationSet/9.png.2’ saved [36660/36660]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ASsAaKJFNae",
        "outputId": "75911b91-7bd2-40a7-ba12-6272d9b44d0d"
      },
      "source": [
        "# import standard PyTorch modules\n",
        "import torch\n",
        "import torch.nn as nn  # Provides many classes and functions to build neural networks (Layer types, activation functions, etc.)\n",
        "import torch.nn.functional as F  \n",
        "import torch.optim as optim  # Provides pre-coded optimization methods (Momentum, SGD, ADAM, etc.)\n",
        "from torch.utils.tensorboard import SummaryWriter # TensorBoard support (Allows the generation of visualization reports for training data, comparing results, etc.)\n",
        "\n",
        "# import torchvision module to handle image manipulation. Also includes the MNIST dataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# calculate train time, writing train data to files etc.\n",
        "import time\n",
        "import pandas as pd\n",
        "import json\n",
        "from IPython.display import clear_output\n",
        "\n",
        "torch.set_printoptions(linewidth=120)\n",
        "torch.set_grad_enabled(True)     # On by default, leave it here for clarity\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7fbd8dad7710>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHGLGRk_Iqk2"
      },
      "source": [
        "# Use standard MNIST dataset\n",
        "trainSet = torchvision.datasets.MNIST(\n",
        "    root = './data/MNIST/train',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")\n",
        "\n",
        "testSet = torchvision.datasets.MNIST(\n",
        "    root = './data/MNIST/test',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Eg52yAJXs82"
      },
      "source": [
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "import os\n",
        "\n",
        "# Functions loads and transforms PIL image into a pytorch tensor (1 x w x h)\n",
        "def imageLoader(image_name, w, h):\n",
        "    loader = transforms.Compose([\n",
        "      transforms.ToTensor()])  \n",
        "    image = Image.open(image_name).convert('L')\n",
        "    image = ImageOps.invert(image)\n",
        "    image = image.resize((w, h))\n",
        "    image = loader(image)\n",
        "    image = image.unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "# Extract images from \"Personal MNIST Validation Set\" folder and covnert to pytorch tensors\n",
        "personalValidationSet = None\n",
        "fileNames = []\n",
        "for fileName in os.listdir(\"PersonalValidationSet\"):\n",
        "  if fileName.endswith(\".png\") or fileName.endswith(\".PNG\"): \n",
        "    fileNames.append(fileName)\n",
        "    img = imageLoader(f\"PersonalValidationSet/{fileName}\", 28, 28)\n",
        "    if personalValidationSet == None: personalValidationSet = img # Edge-case: Insert the 1st tenesor into the validation set manually\n",
        "    else: personalValidationSet = torch.cat((personalValidationSet, img), 0) # Concactonate the tensors (Exp: combines two 1 x 28 x 28 tensors into one 2 x 28 x 28 tensor)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOhl8-cB7Sl_"
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)\n",
        "    self.batchNorm1 = nn.BatchNorm2d(10)\n",
        "    self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)\n",
        "    self.batchNorm2 = nn.BatchNorm2d(20)\n",
        "    # self.fullyConnected1 = nn.Linear(in_features=20*4*4, out_features=120)\n",
        "    # self.batchNorm3 = nn.BatchNorm1d(120)\n",
        "    # self.dropOut1 = nn.Dropout(p=0.25)\n",
        "    self.fullyConnected2 = nn.Linear(in_features=20*4*4, out_features=60)\n",
        "    self.batchNorm4 = nn.BatchNorm1d(60)\n",
        "    self.dropOut2 = nn.Dropout(p=0.25)\n",
        "    self.output = nn.Linear(in_features=60, out_features=10)\n",
        "\n",
        "  def forward(self, t):\n",
        "    # Convolutional Layer 1\n",
        "    t = self.conv1(t)\n",
        "    t = self.batchNorm1(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    # Convolutional layer 2\n",
        "    t = self.conv2(t)\n",
        "    t = self.batchNorm2(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    # # Fully connected layer 1\n",
        "    # t = t.reshape(-1, 20*4*4)\n",
        "    # t = self.fullyConnected1(t)\n",
        "    # t = self.batchNorm3(t)\n",
        "    # t = F.relu(t)\n",
        "    # t = self.dropOut1(t)\n",
        "\n",
        "    # Fully connected layer 2\n",
        "    t = t.reshape(-1, 20*4*4)\n",
        "    t = self.fullyConnected2(t)\n",
        "    t = self.batchNorm4(t)\n",
        "    t = F.relu(t)\n",
        "    t = self.dropOut2(t)\n",
        "\n",
        "    # Fully connected layer 3\n",
        "    t = self.output(t)\n",
        "\n",
        "    # Loss function will be calulated using softmax cross-entropy. Will be done outside of the forward pass method\n",
        "\n",
        "    return t"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_VyJKhoFbhh"
      },
      "source": [
        "from collections import OrderedDict\n",
        "from collections import namedtuple\n",
        "from itertools import product\n",
        "\n",
        "class RunBuilder():\n",
        "  @staticmethod\n",
        "  def getRuns(params):\n",
        "    Run = namedtuple(\"run\", params.keys())\n",
        "    runs = []\n",
        "    for run in product(*params.values()):\n",
        "      runs.append(Run(*run))\n",
        "    return runs"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUEaE2uq0Wi6"
      },
      "source": [
        "# Class which managed \n",
        "# 1. Store the runtimes for each run and its repsective epochs\n",
        "# 2. Store the training data (accuracy, loss, gradients, weights, etc. ) for each run and epoch \n",
        "# 3. Store the data from 1. and 2. into a TensorBoard for further analysis\n",
        "# 4. Store the data from 1. and 2. into a csv and json file for further reference of API extraction\n",
        "class RunManager():\n",
        "  def __init__(self):\n",
        "    # Tracks each epoch's count, loss, accuracy, and duration\n",
        "    self.epochCnt = 0\n",
        "    self.epochLoss = 0\n",
        "    self.epochNumCorrect = 0\n",
        "    self.epochStartTime = 0\n",
        "  \n",
        "    # Tracks each run's count, hyperparameters (Learning rate, batchSize, etc.), data, duration, and validation set accuracy\n",
        "    self.runCnt = 0\n",
        "    self.runParams = None\n",
        "    self.runData = []  # Contains all iterations of the \"epochData\"\n",
        "    self.runStartTime = 0\n",
        "    self.runValidationNumCorrect = 0\n",
        "\n",
        "    # Records neural network model, MNIST dataset, and TensorBoard for storing data\n",
        "    self.network = None\n",
        "    self.trainLoader = None\n",
        "    self.testLoader = None\n",
        "    self.tb = None\n",
        "\n",
        "  def setTestLoader(self, testLoader):\n",
        "    self.testLoader = testLoader\n",
        "\n",
        "  def beginRun(self, runParams, network, trainLoader):\n",
        "    self.runStartTime = time.time()\n",
        "    self.runParams = runParams\n",
        "    self.runCnt += 1\n",
        "\n",
        "    self.network = network\n",
        "    self.trainLoader = trainLoader\n",
        "    self.tb = SummaryWriter(comment=f'-{run}')\n",
        "\n",
        "    images, labels = next(iter(self.trainLoader)) # Subsample a mini-batch of the \"trainLoader\" to be placed as a demo visualization in tensor board\n",
        "    grid = torchvision.utils.make_grid(images) # Mashes the images together side by side to create a grid of images\n",
        "\n",
        "    self.tb.add_image('images', grid)\n",
        "    self.tb.add_graph(self.network, images)\n",
        "\n",
        "  def endRun(self):\n",
        "\n",
        "    runDuration = time.time() - self.runStartTime\n",
        "    accuracy = self.runValidationNumCorrect / len(self.testLoader.dataset)\n",
        "    results = {\n",
        "              \"run\":self.runCnt,\n",
        "              \"epoch\":\"NULL\",\n",
        "              \"loss\":\"NULL\",\n",
        "              \"accuracy\":accuracy,\n",
        "              \"epochDuration\":\"NULL\",\n",
        "              \"runDuration\":runDuration}\n",
        "\n",
        "    # Upload hyper-parameters into \"results\"    \n",
        "    for k, v in self.runParams._asdict().items(): results[k] = v\n",
        "    self.runData.append(results)\n",
        "    df = pd.DataFrame.from_dict(self.runData, orient='columns')\n",
        "\n",
        "    # Display epoch information and show progress\n",
        "    clear_output() # Clear the previous dataframe from the console output\n",
        "    display(df) # Display new dataframe in the console output\n",
        "\n",
        "    self.tb.close()\n",
        "    self.epochCnt = 0\n",
        "    self.run_test_num_correct = 0\n",
        "    self.runValidationAccuracy = 0\n",
        "\n",
        "  def beginEpoch(self):\n",
        "    self.epochStartTime = time.time()\n",
        "    self.epochCnt += 1\n",
        "    self.epochLoss = 0\n",
        "    self.epochNumCorrect = 0\n",
        "\n",
        "  def endEpoch(self):\n",
        "    # Calculate epoch runtime and run runtime (Accumulate)\n",
        "    epochDuration = time.time() - self.epochStartTime\n",
        "    runDuration = time.time() - self.runStartTime\n",
        "\n",
        "    # Cross entropy loss (https://datascience.stackexchange.com/questions/20296/cross-entropy-loss-explanation)\n",
        "    loss = self.epochLoss / len(self.trainLoader.dataset) # Computes cross entropy loss (epochLoss is the total loss across the entire training set over 1 epoch. We average out the loss here by diving by # of images in training set)\n",
        "    accuracy = self.epochNumCorrect / len(self.trainLoader.dataset)\n",
        "\n",
        "    # Record epoch loss and accuracy to TensorBoard \n",
        "    self.tb.add_scalar('Loss', loss, self.epochCnt)\n",
        "    self.tb.add_scalar('Accuracy', accuracy, self.epochCnt)\n",
        "\n",
        "    # Record params to TensorBoard\n",
        "    for name, param in self.network.named_parameters():\n",
        "      self.tb.add_histogram(name, param, self.epochCnt)\n",
        "      self.tb.add_histogram(f'{name}.grad', param.grad, self.epochCnt)\n",
        "\n",
        "    # Write all epoch related data into \"results\" OrderedDict\n",
        "    results = {\n",
        "        \"run\":self.runCnt,\n",
        "        \"epoch\":self.epochCnt,\n",
        "        \"loss\":loss,\n",
        "        \"accuracy\":accuracy,\n",
        "        \"epochDuration\":epochDuration,\n",
        "        \"runDuration\":runDuration,\n",
        "    }\n",
        "    # Record hyper-parameters into \"results\"\n",
        "    for k,v in self.runParams._asdict().items(): results[k] = v\n",
        "    self.runData.append(results)\n",
        "    df = pd.DataFrame.from_dict(self.runData, orient = 'columns')\n",
        "\n",
        "    # Display epoch information and show progress\n",
        "    clear_output()\n",
        "    display(df)\n",
        "\n",
        "  def calculateNumCorrect(self, preds, labels):\n",
        "    numCorrect = preds.argmax(axis=1).eq(labels).sum().item()\n",
        "    return numCorrect\n",
        "\n",
        "  def trackEpochNumCorrect(self, preds, labels):\n",
        "    # Given 2D prediction matrix (Each row contains 1 input cases' predictions) and labels vector, compute the # of correct predictions\n",
        "    numCorrect = self.calculateNumCorrect(preds, labels)\n",
        "    self.epochNumCorrect += numCorrect\n",
        "\n",
        "  def trackRunNumValidationCorrect(self, preds, labels):\n",
        "    numCorrect = self.calculateNumCorrect(preds, labels)\n",
        "    self.runValidationNumCorrect = numCorrect\n",
        "\n",
        "  # Accumulate loss for entire epoch\n",
        "  # Recieves the average loss of a batch. Mutliply average batch loss by batch size in order to get total batch loss \n",
        "  def trackLoss(self, loss):\n",
        "    self.epochLoss += loss.item() * self.trainLoader.batch_size\n",
        "\n",
        "  # save end results of all runs into csv, json for further analysis\n",
        "  def save(self, fileName):\n",
        "\n",
        "    pd.DataFrame.from_dict(\n",
        "        self.runData, \n",
        "        orient = 'columns',\n",
        "    ).to_csv(f'{fileName}.csv')\n",
        "\n",
        "    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
        "      json.dump(self.runData, f, ensure_ascii=False, indent=4)\n",
        "  \n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLQdQv4yGv-n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "d6698102-6ee6-4b2f-89a7-6e426bd70beb"
      },
      "source": [
        "m = RunManager()\n",
        "networks = []\n",
        "params = OrderedDict( \n",
        "                   lr=[0.001, 0.01],\n",
        "                   batchSize=[100, 1000],\n",
        "                   shuffle=[True, False])\n",
        "# params = OrderedDict( \n",
        "#                    lr=[0.01],\n",
        "#                    batchSize=[30],\n",
        "#                    shuffle=[True])\n",
        "epochs = 3\n",
        "\n",
        "\n",
        "testLoader = torch.utils.data.DataLoader(testSet, batch_size=10000)\n",
        "m.setTestLoader(testLoader)\n",
        "for run in RunBuilder.getRuns(params):\n",
        "  network = Network()\n",
        "  trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=run.batchSize, shuffle=run.shuffle)\n",
        "  print(len(trainLoader), trainLoader.batch_size)\n",
        "  optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
        "\n",
        "  m.beginRun(run, network, trainLoader)\n",
        "  for epoch in range(epochs):\n",
        "    m.beginEpoch()\n",
        "    for batch in trainLoader:\n",
        "      network.eval() # Set model to evaluation mode\n",
        "      images = batch[0]\n",
        "      labels = batch[1]\n",
        "      preds = network(images)\n",
        "      loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "      network.train() # Set model to training mode\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      m.trackEpochNumCorrect(preds, labels)\n",
        "      m.trackLoss(loss)\n",
        "\n",
        "    m.endEpoch()\n",
        "\n",
        "  for batch in testLoader:\n",
        "    network.eval() # Set model to evaluation mode\n",
        "    images = batch[0]\n",
        "    labels = batch[1]\n",
        "    preds = network(images)\n",
        "    m.trackRunNumValidationCorrect(preds, labels)\n",
        "\n",
        "  networks.append(network)\n",
        "  m.endRun()\n",
        "m.save(\"Saved\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run</th>\n",
              "      <th>epoch</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>epochDuration</th>\n",
              "      <th>runDuration</th>\n",
              "      <th>lr</th>\n",
              "      <th>batchSize</th>\n",
              "      <th>shuffle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.339230</td>\n",
              "      <td>0.900667</td>\n",
              "      <td>28.720166</td>\n",
              "      <td>28.938510</td>\n",
              "      <td>0.001</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.091329</td>\n",
              "      <td>0.972083</td>\n",
              "      <td>29.750858</td>\n",
              "      <td>58.832733</td>\n",
              "      <td>0.001</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   run  epoch      loss  accuracy  ...  runDuration     lr  batchSize  shuffle\n",
              "0    1      1  0.339230  0.900667  ...    28.938510  0.001        100     True\n",
              "1    1      2  0.091329  0.972083  ...    58.832733  0.001        100     True\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaQ2AV8vnsUx"
      },
      "source": [
        "torch.save(networks[-1].state_dict(), \"Model\") # Save trained neural network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq8_hTNajqQ0"
      },
      "source": [
        "# Evaluate personal validation set\n",
        "\n",
        "# Load CNN\n",
        "completedModel = Network()\n",
        "completedModel.load_state_dict(torch.load(\"Model\"))\n",
        "completedModel.eval() # Switch from training to evaluation mode\n",
        "\n",
        "# Personal validation set predictions\n",
        "\n",
        "pred = completedModel(personalValidationSet)\n",
        "predClass = pred.argmax(axis=1)\n",
        "\n",
        "# Display predictions\n",
        "print(\"Ground Truth: \")\n",
        "print(fileNames)\n",
        "print(\"Predictions: \")\n",
        "print(predClass)\n",
        "print(\"All Scores\")\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UbHPvFp4IYr"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}